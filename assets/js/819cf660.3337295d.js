"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[2504],{3905:function(e,t,n){n.d(t,{Zo:function(){return h},kt:function(){return p}});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function c(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?c(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):c(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},c=Object.keys(e);for(a=0;a<c.length;a++)n=c[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var c=Object.getOwnPropertySymbols(e);for(a=0;a<c.length;a++)n=c[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),l=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},h=function(e){var t=l(e.components);return a.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,c=e.originalType,s=e.parentName,h=i(e,["components","mdxType","originalType","parentName"]),d=l(n),p=r,m=d["".concat(s,".").concat(p)]||d[p]||u[p]||c;return n?a.createElement(m,o(o({ref:t},h),{},{components:n})):a.createElement(m,o({ref:t},h))}));function p(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var c=n.length,o=new Array(c);o[0]=d;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i.mdxType="string"==typeof e?e:r,o[1]=i;for(var l=2;l<c;l++)o[l]=n[l];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},7873:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return i},contentTitle:function(){return s},metadata:function(){return l},toc:function(){return h},default:function(){return d}});var a=n(7462),r=n(3366),c=(n(7294),n(3905)),o=["components"],i={id:"Cachebench_Overview",title:"Cachebench Overview"},s="What is cachebench?",l={unversionedId:"Cache_Library_User_Guides/Cachebench_Overview",id:"Cache_Library_User_Guides/Cachebench_Overview",isDocsHomePage:!1,title:"Cachebench Overview",description:"CacheBench is a benchmark suite that can read a workload configuration file, simulate cache behavior as stipulated in the config, and produce performance summary for the simulated cache. Results include metrics such as hit rate, evictions, write rate to flash cache, latency, etc. The workload configs can be hand-written by a human, produced by a workload analyzer, or backed by raw production cachelib traces. The main customization points into CacheBench are through writing workload configs or custom workload generators.",source:"@site/docs/Cache_Library_User_Guides/Cachebench_Overview.md",sourceDirName:"Cache_Library_User_Guides",slug:"/Cache_Library_User_Guides/Cachebench_Overview",permalink:"/docs/Cache_Library_User_Guides/Cachebench_Overview",editUrl:"https://github.com/facebook/docusaurus/edit/master/website/docs/Cache_Library_User_Guides/Cachebench_Overview.md",version:"current",frontMatter:{id:"Cachebench_Overview",title:"Cachebench Overview"},sidebar:"someSidebar",previous:{title:"Structured Cache",permalink:"/docs/Cache_Library_User_Guides/Structured_Cache"},next:{title:"Developing for Cachebench",permalink:"/docs/Cache_Library_User_Guides/Developing_for_Cachebench"}},h=[{value:"Tao Leader",id:"tao-leader",children:[]},{value:"Memcache WC",id:"memcache-wc",children:[]},{value:"Memcache reg",id:"memcache-reg",children:[]},{value:"Plotting latency stats",id:"plotting-latency-stats",children:[]}],u={toc:h};function d(e){var t=e.components,i=(0,r.Z)(e,o);return(0,c.kt)("wrapper",(0,a.Z)({},u,i,{components:t,mdxType:"MDXLayout"}),(0,c.kt)("h1",{id:"what-is-cachebench"},"What is cachebench?"),(0,c.kt)("p",null,"CacheBench is a benchmark suite that can read a workload configuration file, simulate cache behavior as stipulated in the config, and produce performance summary for the simulated cache. Results include metrics such as hit rate, evictions, write rate to flash cache, latency, etc. The workload configs can be hand-written by a human, produced by a workload analyzer, or backed by raw production cachelib traces. The main customization points into CacheBench are through writing workload configs or custom workload generators."),(0,c.kt)("p",null,(0,c.kt)("img",{src:n(8567).Z})),(0,c.kt)("h1",{id:"downloading-the-latest-package"},"Downloading the latest package"),(0,c.kt)("pre",null,(0,c.kt)("code",{parentName:"pre",className:"language-shell"},"mkdir cachebench; cd cachebench;\nfbpkg.fetch cachelib.cachebench:latest\n")),(0,c.kt)("h1",{id:"running-cachebench-on-t10-hw"},"Running cachebench on T10 HW"),(0,c.kt)("p",null,"Cachebench has three configs packaged for flash HW validation. These are under ",(0,c.kt)("inlineCode",{parentName:"p"},"test_configs/hw_test_configs/<service-domain>"),'. Currently, we have "tao-leader", "memcache-reg", and "memcache-wc" which represent three distinct workloads in the cache space.'),(0,c.kt)("p",null,"To run any of them, first ensure that the machine has sufficient free memory (50+GB)."),(0,c.kt)("h2",{id:"tao-leader"},"Tao Leader"),(0,c.kt)("pre",null,(0,c.kt)("code",{parentName:"pre",className:"language-shell"},"./cachebench --json_test_config test_configs/ssd_perf/tao_leader/config.json --progress_stats_file=/tmp/tao_leader.log\n")),(0,c.kt)("h2",{id:"memcache-wc"},"Memcache WC"),(0,c.kt)("pre",null,(0,c.kt)("code",{parentName:"pre",className:"language-shell"},"./cachebench --json_test_config test_configs/ssd_perf/memcache_l2_wc/config.json  --progress_stats_file=/tmp/mc-l2-wc.log\n")),(0,c.kt)("h2",{id:"memcache-reg"},"Memcache reg"),(0,c.kt)("pre",null,(0,c.kt)("code",{parentName:"pre",className:"language-shell"},"./cachebench --json_test_config test_configs/ssd_perf/memcache_l2_reg/config.json  --progress_stats_file=/tmp/mc-l2-reg.log\n")),(0,c.kt)("p",null,"This will stream the benchmark progress to the terminal and also log detailed stats to the specified file. The log file would contain a periodic dump of the latency  and cache stats, which  can then be plotted using some of the scripts.  If the stats are not intended to be collected, then skip the option ",(0,c.kt)("inlineCode",{parentName:"p"},"--progress_stats_file"),"."),(0,c.kt)("h1",{id:"analyzing-the-performance-metrics"},"Analyzing the performance metrics"),(0,c.kt)("p",null,"While cachebench runs, it will report some stats through the fb303 port. In addition, one can monitor the flash metrics from ODS on IOPS, nand writes etc. cachebench also periodically dumps some stats to the stdout, that can be processed later on."),(0,c.kt)("h2",{id:"plotting-latency-stats"},"Plotting latency stats"),(0,c.kt)("p",null,"The stats output can be parsed to plot NVM latency information over time. To do this, first ensure ",(0,c.kt)("inlineCode",{parentName:"p"},"gnuplot")," is installed:"),(0,c.kt)("pre",null,(0,c.kt)("code",{parentName:"pre",className:"language-shell"},"yum install gnuplot\n")),(0,c.kt)("p",null,"Then run this command to get the latency stats:"),(0,c.kt)("pre",null,(0,c.kt)("code",{parentName:"pre",className:"language-shell"},"./vizualize/extract_latency.sh /tmp/tao_leader.log\n")),(0,c.kt)("p",null,"This should produce a tsv file for read latency, a tsv file for write latency, and the corresponding ",(0,c.kt)("inlineCode",{parentName:"p"},"png")," files that have the graphs plotted."))}d.isMDXComponent=!0},8567:function(e,t,n){t.Z=n.p+"assets/images/cachebench-25d1d476ed27af8ec3a0b5033571dd1a.png"}}]);